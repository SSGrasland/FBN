{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b117319d-d154-4dd4-b88f-215368f9b07d",
   "metadata": {},
   "source": [
    "# FBN Scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194ea77-f631-43b4-9a4e-62acfc5aad35",
   "metadata": {},
   "source": [
    "## Creating Folder to Save Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917998a8-6ec6-4903-b1a5-524ca76b466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder name\n",
    "folder_name = \"4.6\"\n",
    "\n",
    "# Create the folder\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Check if the folder was created\n",
    "if os.path.exists(folder_name):\n",
    "    print(f\"Folder '{folder_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to create folder '{folder_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32bf44-5ac5-4e29-bdee-6dab80496e27",
   "metadata": {},
   "source": [
    "## Converting From PDF to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c914fb3-6ffe-4a2b-b170-2783d9a82442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the needed library to convert PDF to text\n",
    "import pdfplumber\n",
    "\n",
    "#extracting the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Replace 'your_pdf_file.pdf' with the actual path to your PDF file\n",
    "pdf_path = r\"C:\\Users\\salom\\OneDrive\\Área de Trabalho\\FBN New\\FBN\\Issues\\4.6.pdf\"\n",
    "\n",
    "#variable containing text called extracted_text\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ca3dc-ed82-47cf-90f0-480f9544b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the text file \n",
    "\n",
    "with open('4.6/4.6_Issue_Text.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a4d37-90f8-4627-ad37-696b1e275df1",
   "metadata": {},
   "source": [
    "## ISBNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd9195-4b8e-4032-99be-cb446243c1d1",
   "metadata": {},
   "source": [
    "### Parsing ISBNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6941c-378c-4bcf-ab8f-a77f4ee4b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting ISBNs from thext \n",
    "#importing the library\n",
    "import re\n",
    "\n",
    "#defining the regex used \n",
    "def extract_isbns(text):\n",
    "    # Define a regex pattern to match strings of numbers with dashes\n",
    "    isbn_pattern = r\"((978[-– ])?[0-9][0-9-– ]{10}[-– ][0-9xX])|((978)?[0-9]{9}[0-9Xx])\"\n",
    "\n",
    "    # Find all matches of the ISBN pattern in the text\n",
    "    isbns = re.findall(isbn_pattern, text)\n",
    "\n",
    "    return isbns\n",
    "\n",
    "# Extract ISBNs from the example text\n",
    "isbns_found = extract_isbns(extracted_text)\n",
    "\n",
    "# Extract only the portions with numbers and dashes\n",
    "isbns_found = [isbn[0] for isbn in isbns_found]\n",
    "\n",
    "#print(\"Cleaned ISBNs:\", isbns_found)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5d092-976a-4cfc-91f6-6b441de5a712",
   "metadata": {},
   "source": [
    "### ISBN Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2429e20a-e67d-4ec7-b97f-3c3d1a28343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe that has ISBNs and the page numbers where found \n",
    "\n",
    "#importing necessary libaries\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_isbns_from_text(text):\n",
    "    # Define the ISBN regex pattern\n",
    "    isbn_pattern = re.compile(r\"((978[-– ])?[0-9][0-9-– ]{10}[-– ][0-9xX])|((978)?[0-9]{9}[0-9Xx])\")\n",
    "\n",
    "    # Find all ISBNs in the text\n",
    "    isbns_found = isbn_pattern.findall(text)\n",
    "    return isbns_found\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    data = {'PageNumber': [], 'Text': [], 'ISBNs': []}\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            # Add page number and corresponding text to the data dictionary\n",
    "            data['PageNumber'].append(i)\n",
    "            text = page.extract_text()\n",
    "            data['Text'].append(text)\n",
    "            \n",
    "            # Extract ISBNs from the text\n",
    "            isbns_found = extract_isbns_from_text(text)\n",
    "            isbns_found = [isbn[0] for isbn in isbns_found]\n",
    "            data['ISBNs'].append(isbns_found)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Replace 'your_pdf_file.pdf' with the actual path to your PDF file\n",
    "pdf_path = r\"C:\\Users\\salom\\OneDrive\\Área de Trabalho\\FBN New\\FBN\\Issues\\4.6.pdf\"\n",
    "df = extract_text_from_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7b63d-70dc-4b6e-b2c2-cc7389b93c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624f764-8300-445c-826b-259da3a7cf03",
   "metadata": {},
   "source": [
    "### Downloading List of ISBNs and Page Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab76cd-fe2c-4063-bc68-6cc4206f0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change issue number\n",
    "df.to_csv('4.6/4.6_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9417-5b9e-4f7f-97b0-4e166e8c814a",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda67e8b-e10c-4a77-9c61-8ae8513c1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "api_key = '52084_9ddf62aeaa4a39b5485d9b7fb69dd5a8'\n",
    "isbns_to_process = isbns_found  # Replace with the original list of ISBNs you want to process\n",
    "\n",
    "# Removing Duplicates\n",
    "isbns_to_process = list(set(isbns_to_process))\n",
    "\n",
    "base_url = 'https://api2.isbndb.com/book/'\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, calls_per_second):\n",
    "        self.calls_per_second = calls_per_second\n",
    "        self.interval = 1.0 / calls_per_second\n",
    "        self.last_call = 0\n",
    "\n",
    "    def wait(self):\n",
    "        now = time.time()\n",
    "        elapsed = now - self.last_call\n",
    "        if elapsed < self.interval:\n",
    "            time.sleep(self.interval - elapsed)\n",
    "        self.last_call = time.time()\n",
    "\n",
    "rate_limiter = RateLimiter(3)  # Allow 3 calls per second\n",
    "\n",
    "with open('book_information.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    fieldnames = ['ISBN', 'Title', 'Author', 'Publisher', 'Pages', 'Date Published', 'Subjects', 'Binding', 'Synopsis', 'Language', 'Edition', 'Dimensions', 'MSRP', 'Image', 'Status']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for isbn in isbns_to_process:\n",
    "        url = f'{base_url}{isbn}'\n",
    "        headers = {'Authorization': api_key}\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            book_info = response.json().get('book', {})\n",
    "            writer.writerow({\n",
    "                'ISBN': isbn,\n",
    "                'Title': book_info.get('title', ''),\n",
    "                'Author': ', '.join(book_info.get('authors', [])),\n",
    "                'Publisher': book_info.get('publisher', ''),\n",
    "                'Pages': book_info.get('pages', ''),\n",
    "                'Date Published': book_info.get('date_published', ''),\n",
    "                'Subjects': ', '.join(book_info.get('subjects', [])),  # Add subjects here\n",
    "                'Binding': book_info.get('binding', ''),\n",
    "                'Synopsis': book_info.get('synopsis', ''),\n",
    "                'Language': book_info.get('language', ''),\n",
    "                'Edition': book_info.get('edition', ''),\n",
    "                'Dimensions': book_info.get('dimensions', ''),\n",
    "                'MSRP': book_info.get('msrp', ''),\n",
    "                'Image': book_info.get('image', ''),\n",
    "                'Status': 'Success'\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Error for ISBN {isbn}: {response.status_code}\")\n",
    "            writer.writerow({\n",
    "                'ISBN': isbn,\n",
    "                'Status': 'Error',\n",
    "                'Title': '',\n",
    "                'Author': '',\n",
    "                'Publisher': '',\n",
    "                'Pages': '',\n",
    "                'Date Published': '',\n",
    "                'Binding': '',\n",
    "                'Synopsis': '',\n",
    "                'Language': '',\n",
    "                'Edition': '',\n",
    "                'Dimensions': '',\n",
    "                'MSRP': '',\n",
    "                'Image': ''\n",
    "            })\n",
    "\n",
    "        rate_limiter.wait()  # Pause according to the rate limiter\n",
    "\n",
    "print(\"CSV file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c80247-34ba-4e8a-9283-5616bdbfdada",
   "metadata": {},
   "source": [
    "## Joining Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44227a7d-ba15-4fdc-9ff4-fab9d706f6c5",
   "metadata": {},
   "source": [
    "### Renaming to ISBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded2f2a-1145-4923-94cc-8ae59592ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'ISBNs' is the current column name and 'ISBN' is the desired column name\n",
    "df.rename(columns={'ISBNs': 'ISBN'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e511f-f9b6-47d2-9688-a425b2486650",
   "metadata": {},
   "source": [
    "### Adding Page Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272a8ef-2ab5-4d4d-9256-e2b53375516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = df[['PageNumber', 'ISBN']]\n",
    "page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a0dfe-4f1e-4433-9f6b-e774bfa1ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "page['ISBN'] = page['ISBN'].astype(str).str.replace('[\\[\\]\\'\\\"]', '')\n",
    "page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57423fac-4a2c-4abc-a8c1-06aa0b0c42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split values on comma and explode to create new rows\n",
    "page['ISBN'] = page['ISBN'].str.split(', ')\n",
    "page = page.explode('ISBN')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "page.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf70932-bfd6-43c5-81f3-1925f37dd706",
   "metadata": {},
   "source": [
    "### Opening Scraped Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd779854-1f80-4a27-81e1-fa4aa464c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r'C:\\Users\\salom\\OneDrive\\Área de Trabalho\\FBN New\\FBN\\notebooks\\book_information.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "info = pd.read_csv(file_path)\n",
    "\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04158c11-8052-4e22-8b39-1a71199f91c8",
   "metadata": {},
   "source": [
    "### Joining it With Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490094c-e113-40d1-8b73-448451377362",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(info, page, on='ISBN', how='left')\n",
    "merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ff07c7-9d6c-4fbf-83a6-495d32abd0a9",
   "metadata": {},
   "source": [
    "### Adding a Column For Issue and Volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef5b93-72a9-43dc-86ea-af8e8a434aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['Volume & Issue'] = '4.6'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9348b-800d-4e86-b748-ece1ddc56813",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d32f5-90a7-48cc-8144-7dae531735c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all duplicate rows from the DataFrame\n",
    "merge = merge.drop_duplicates(keep=False)\n",
    "\n",
    "# Reset the index after dropping duplicates\n",
    "merge.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5599bf5f-5340-438a-b1f9-3b17d956dcbb",
   "metadata": {},
   "source": [
    "### Downloading Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634f8f8-9212-4818-8bbc-60e933a6c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'merge' is your DataFrame\n",
    "merge.to_csv('4.6/4.6_booklist.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5257e-1bb3-4174-97f6-119e2136926c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca857dc3-f43e-4dc7-854d-6ffed5604ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
